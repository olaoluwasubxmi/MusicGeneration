{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = ('yemusic.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 266894 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 266894 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let the suicide doors up\n",
      "I threw suicides on the tour bus\n",
      "I threw suicides on the private jet\n",
      "You know what that mean, I'm fly to death\n",
      "I step in Def Jam buildin' like I'm the shit\n",
      "Tell 'em give me fifty million or I'ma quit\n",
      "Most rappers' taste\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts = ['abcdefg', 'xyz']\n",
    "\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[57, 58, 59, 60, 61, 62, 63], [80, 81, 82]]>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'abcdefg', b'xyz'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(266894,), dtype=int64, numpy=array([42, 61, 76, ..., 77, 16, 16], dtype=int64)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L\n",
      "e\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "s\n",
      "u\n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'L' b'e' b't' b' ' b't' b'h' b'e' b' ' b's' b'u' b'i' b'c' b'i' b'd'\n",
      " b'e' b' ' b'd' b'o' b'o' b'r' b's' b' ' b'u' b'p' b'\\r' b'\\n' b'I' b' '\n",
      " b't' b'h' b'r' b'e' b'w' b' ' b's' b'u' b'i' b'c' b'i' b'd' b'e' b's'\n",
      " b' ' b'o' b'n' b' ' b't' b'h' b'e' b' ' b't' b'o' b'u' b'r' b' ' b'b'\n",
      " b'u' b's' b'\\r' b'\\n' b'I' b' ' b't' b'h' b'r' b'e' b'w' b' ' b's' b'u'\n",
      " b'i' b'c' b'i' b'd' b'e' b's' b' ' b'o' b'n' b' ' b't' b'h' b'e' b' '\n",
      " b'p' b'r' b'i' b'v' b'a' b't' b'e' b' ' b'j' b'e' b't' b'\\r' b'\\n' b'Y'\n",
      " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Let the suicide doors up\\r\\nI threw suicides on the tour bus\\r\\nI threw suicides on the private jet\\r\\nYou '\n",
      "b\"know what that mean, I'm fly to death\\r\\nI step in Def Jam buildin' like I'm the shit\\r\\nTell 'em give me\"\n",
      "b\" fifty million or I'ma quit\\r\\nMost rappers' taste level ain't at my waist level\\r\\nTurn up the bass 'til\"\n",
      "b\" it's up-in-yo-face level\\r\\nDon't do no press but I get the most press kit\\r\\nPlus, yo, my bitch make yo\"\n",
      "b\"ur bitch look like Precious\\r\\nSomethin' 'bout Mary, she gone off that molly\\r\\nNow the whole party is me\"\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "  print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
       " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_input_target(list(\"Tensorflow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b'Let the suicide doors up\\r\\nI threw suicides on the tour bus\\r\\nI threw suicides on the private jet\\r\\nYou'\n",
      "Target: b'et the suicide doors up\\r\\nI threw suicides on the tour bus\\r\\nI threw suicides on the private jet\\r\\nYou '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 96) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     multiple                  24576     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  98400     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,061,280\n",
      "Trainable params: 4,061,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 84, 88, 41, 17, 78, 24, 66, 82, 43, 13, 24,  9, 19, 32, 55, 84,\n",
       "       15, 14, 78, 90, 39, 18, 88, 64, 90, 12, 48, 19, 89, 24, 51,  4, 32,\n",
       "        9, 49, 84,  0, 16, 27, 81, 87, 23, 28, 39, 42, 52, 54, 34, 31, 44,\n",
       "       32, 83, 93, 29,  0, 16, 42, 55, 25, 11, 92, 25, 80, 57, 61, 51, 64,\n",
       "       26, 46,  0,  8, 94, 45, 39, 89, 22, 54, 57, 53, 32, 15,  0, 44, 40,\n",
       "       91, 78, 27, 91, 93, 34, 26, 53, 83, 77, 95, 74, 88, 29,  6],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'o exciting\\r\\n\\r\\nDinner with Anna Wintour, racing with Anja Rubik\\r\\nI told you motherfuckers it was more'\n",
      "\n",
      "Next Char Predictions:\n",
      " b\"O\\xc2\\xb7\\xc3\\xb1K/v6jzM+6'1BY\\xc2\\xb7-,v\\xc4\\x81I0\\xc3\\xb1h\\xc4\\x81*R1\\xc3\\xb36U!B'S\\xc2\\xb7[UNK].9y\\xc3\\xad5:ILVXDANB~\\xe2\\x80\\x9c;[UNK].LY7)\\xe2\\x80\\x937xaeUh8P[UNK]&\\xe2\\x80\\x9dOI\\xc3\\xb34XaWB-[UNK]NJ\\xe2\\x80\\x8bv9\\xe2\\x80\\x8b\\xe2\\x80\\x9cD8W~u\\xe2\\x80\\xa6r\\xc3\\xb1;#\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 96)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.5642743, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.992905"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "41/41 [==============================] - 80s 2s/step - loss: 3.4116\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 81s 2s/step - loss: 2.5505\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 80s 2s/step - loss: 2.3264\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 82s 2s/step - loss: 2.2178\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 83s 2s/step - loss: 2.1162\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 86s 2s/step - loss: 2.0138\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 82s 2s/step - loss: 1.9223\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 82s 2s/step - loss: 1.8415\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 81s 2s/step - loss: 1.7721\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 81s 2s/step - loss: 1.7081\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 82s 2s/step - loss: 1.6501\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 85s 2s/step - loss: 1.5984\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 84s 2s/step - loss: 1.5485\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 86s 2s/step - loss: 1.4972\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 85s 2s/step - loss: 1.4521\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 83s 2s/step - loss: 1.4032\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 84s 2s/step - loss: 1.3570\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 84s 2s/step - loss: 1.3068\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 84s 2s/step - loss: 1.2554\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 82s 2s/step - loss: 1.1995\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 83s 2s/step - loss: 1.1430\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 83s 2s/step - loss: 1.0817\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 83s 2s/step - loss: 1.0187\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 83s 2s/step - loss: 0.9506\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 83s 2s/step - loss: 0.8777\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 85s 2s/step - loss: 0.8011\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 82s 2s/step - loss: 0.7244\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 84s 2s/step - loss: 0.6455\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 81s 2s/step - loss: 0.5682\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 81s 2s/step - loss: 0.4925\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 81s 2s/step - loss: 0.4264\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 81s 2s/step - loss: 0.3635\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 81s 2s/step - loss: 0.3063\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 81s 2s/step - loss: 0.2596\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 82s 2s/step - loss: 0.2199\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 81s 2s/step - loss: 0.1872\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 80s 2s/step - loss: 0.1597\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 81s 2s/step - loss: 0.1388\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 81s 2s/step - loss: 0.1227\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 81s 2s/step - loss: 0.1113\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 81s 2s/step - loss: 0.1024\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 81s 2s/step - loss: 0.0954\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 82s 2s/step - loss: 0.0896\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 82s 2s/step - loss: 0.0864\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 80s 2s/step - loss: 0.0823\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 82s 2s/step - loss: 0.0803\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 83s 2s/step - loss: 0.0782\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 81s 2s/step - loss: 0.0767\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 82s 2s/step - loss: 0.0752\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 82s 2s/step - loss: 0.0746\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot assign value to variable ' my_model/embedding_2/embeddings:0': Shape mismatch.The variable shape (96, 256), and the assigned value shape (88, 256) are incompatible.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25160/559420998.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'donda.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Subxmi\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Subxmi\\Anaconda3\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   4300\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4301\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4302\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4303\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4304\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot assign value to variable ' my_model/embedding_2/embeddings:0': Shape mismatch.The variable shape (96, 256), and the assigned value shape (88, 256) are incompatible."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yeezy: Ye!\"\n",
      "It's finned friends like I'm crazy\n",
      "Don't ever think that'd phines on 'em\n",
      "Me and Jor a feel life, n'w things\n",
      "They was leaning is and I'm looking for the one kers that's hop grount\n",
      "You know what though? You my father be with you first slow\n",
      "Try and make it to the party 'fore we finally dog\n",
      "I feel like one day I need a stylist can't let her fuck it all\n",
      "When it still look goine it ain't no channels\n",
      "But it's quite ok for a gangsta to wear sandash\n",
      "Like killin't the hell you think these bitches comin' at me fo'\n",
      "But since they all fall in my Palm, I talk my shrestm\n",
      "\n",
      "Now, I make noise boothers, that's a seaf where the back\n",
      "Ore we all go\n",
      "Not just by myself, lookin' for niggas like where's Waldo\n",
      "She got the ponice, that's how I feel\n",
      "To be down, you must appeal\n",
      "That's up to the morgue ne tried to give and just like you\n",
      "But this is for everything I want now?\n",
      "Now everybody got through the pain and it mothers\n",
      "Told Kay, \"Don't drunk and hot girl\n",
      "You want to sit down, huh, st \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 2.800637722015381\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['Yeezy:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
